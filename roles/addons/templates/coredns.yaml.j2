---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: coredns-autoscaler
  namespace: kube-system
  labels:
    k8s-app: coredns-autoscaler
    kubernetes.io/cluster-service: "true"
    kubernetes.io/name: "kube-dns"
    app.kubernetes.io/name: coredns-autoscaler
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: coredns
  namespace: kube-system
  labels:
    k8s-app: "kube-dns"
    kubernetes.io/name: "kube-dns"
    app.kubernetes.io/name: kube-dns
---
kind: ConfigMap
apiVersion: v1
metadata:
  name: coredns-autoscaler
  namespace:  kube-system
  labels:
    k8s-app: coredns-autoscaler
    kubernetes.io/cluster-service: "true"
    kubernetes.io/name: "kube-dns"
    app.kubernetes.io/name: coredns-autoscaler
data:
  # When cluster is using large nodes(with more cores), "coresPerReplica" should dominate.
  # If using small nodes, "nodesPerReplica" should dominate.
  linear: |-
    {
      "coresPerReplica": 1,
      "nodesPerReplica": 2,
      "preventSinglePointFailure": true,
      "min": 1,
      "max": 3,
      "includeUnschedulableNodes": false
    }
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: kube-dns
  namespace: kube-system
  labels:
    k8s-app: "kube-dns"
    kubernetes.io/cluster-service: "true"
    kubernetes.io/name: "kube-dns"
    app.kubernetes.io/name: kube-dns
data:
  Corefile: |-
    .:53 {
        errors
        health {
            lameduck 5s
        }
        ready
        kubernetes cluster.shenzhen in-addr.arpa ip6.arpa {
            pods insecure
            fallthrough in-addr.arpa ip6.arpa
            ttl 30
        }
        prometheus 0.0.0.0:9153
        forward . /etc/resolv.conf
        cache 30
        loop
        reload
        loadbalance
    }
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: coredns-autoscaler
  labels:
    helm.sh/chart: "coredns-1.15.0"
    k8s-app: coredns-autoscaler
    kubernetes.io/cluster-service: "true"
    kubernetes.io/name: "kube-dns"
    app.kubernetes.io/name: coredns-autoscaler
rules:
  - apiGroups: [""]
    resources: ["nodes"]
    verbs: ["list","watch"]
  - apiGroups: [""]
    resources: ["replicationcontrollers/scale"]
    verbs: ["get", "update"]
  - apiGroups: ["extensions", "apps"]
    resources: ["deployments/scale", "replicasets/scale"]
    verbs: ["get", "update"]
# Remove the configmaps rule once below issue is fixed:
# kubernetes-incubator/cluster-proportional-autoscaler#16
  - apiGroups: [""]
    resources: ["configmaps"]
    verbs: ["get", "create"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: coredns
  labels:
    k8s-app: "kube-dns"
    kubernetes.io/cluster-service: "true"
    kubernetes.io/name: "kube-dns"
    app.kubernetes.io/name: kube-dns
rules:
- apiGroups:
  - ""
  resources:
  - endpoints
  - services
  - pods
  - namespaces
  verbs:
  - list
  - watch
- apiGroups:
  - discovery.k8s.io
  resources:
  - endpointslices
  verbs:
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: coredns-autoscaler
  labels:
    k8s-app: coredns-autoscaler
    kubernetes.io/cluster-service: "true"
    kubernetes.io/name: "kube-dns"
    app.kubernetes.io/name: coredns-autoscaler
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: coredns-autoscaler
subjects:
- kind: ServiceAccount
  name: coredns-autoscaler
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: coredns
  labels:
    k8s-app: "kube-dns"
    kubernetes.io/cluster-service: "true"
    kubernetes.io/name: "kube-dns"
    app.kubernetes.io/name: kube-dns
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: coredns
subjects:
- kind: ServiceAccount
  name: coredns
  namespace: kube-system
---
apiVersion: v1
kind: Service
metadata:
  name: kube-dns
  namespace: kube-system
  labels:
    k8s-app: "kube-dns"
    kubernetes.io/cluster-service: "true"
    kubernetes.io/name: "kube-dns"
    app.kubernetes.io/name: kube-dns
  annotations:
    prometheus.io/port: "9153"
    prometheus.io/scrape: "true"
spec:
  selector:
    k8s-app: "kube-dns"
    app.kubernetes.io/name: kube-dns
  clusterIP: 10.80.0.2 
  ports:
  - {port: 53, protocol: UDP, name: udp-53}
  - {port: 53, protocol: TCP, name: tcp-53}
  type: ClusterIP
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: coredns-autoscaler
  namespace: kube-system
  labels:
    k8s-app: coredns-autoscaler
    kubernetes.io/cluster-service: "true"
    kubernetes.io/name: "kube-dns"
    app.kubernetes.io/name: coredns-autoscaler
spec:
  selector:
    matchLabels:
      k8s-app: coredns-autoscaler
      app.kubernetes.io/name: coredns-autoscaler
  template:
    metadata:
      labels:
        k8s-app: coredns-autoscaler
        app.kubernetes.io/name: coredns-autoscaler
      annotations:
        checksum/configmap: c608379a7d724ba481ce60a9b16665c3cbef96738abeebc7f3e838af99934ce1
        scheduler.alpha.kubernetes.io/critical-pod: ''
        scheduler.alpha.kubernetes.io/tolerations: '[{"key":"CriticalAddonsOnly", "operator":"Exists"}]'
    spec:
      serviceAccountName: coredns-autoscaler
      containers:
      - name: autoscaler
        image: "registry.cn-hangzhou.aliyuncs.com/qcloud-gcr/cluster-proportional-autoscaler-amd64:1.8.0"
        imagePullPolicy: IfNotPresent
        resources:
          limits:
            cpu: 100m
            memory: 100Mi
          requests:
            cpu: 20m
            memory: 10Mi
        command:
          - /cluster-proportional-autoscaler
          - --namespace=kube-system
          - --configmap=coredns-autoscaler
          - --target=Deployment/coredns
          - --logtostderr=true
          - --v=2
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: coredns
  namespace: kube-system
  labels:
    k8s-app: "kube-dns"
    kubernetes.io/cluster-service: "true"
    kubernetes.io/name: "kube-dns"
    app.kubernetes.io/name: kube-dns
    app.kubernetes.io/version: "1.8.0"
spec:
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 25%
  selector:
    matchLabels:
      k8s-app: "kube-dns"
      app.kubernetes.io/name: kube-dns
  template:
    metadata:
      labels:
        k8s-app: "kube-dns"
        app.kubernetes.io/name: kube-dns
      annotations:
        checksum/config: 02c19cbc1e9d1c8e4678c4a6171023cb0967fa8d559ac01e9325e6cc8c448bb5
        scheduler.alpha.kubernetes.io/critical-pod: ''
        scheduler.alpha.kubernetes.io/tolerations: '[{"key":"CriticalAddonsOnly", "operator":"Exists"}]'
    spec:
      terminationGracePeriodSeconds: 30
      serviceAccountName: coredns
      dnsPolicy: Default
      containers:
      - name: "coredns"
        image: "coredns/coredns:1.8.0"
        imagePullPolicy: IfNotPresent
        args: [ "-conf", "/etc/coredns/Corefile" ]
        volumeMounts:
        - name: config-volume
          mountPath: /etc/coredns
        resources:
          limits:
            cpu: 100m
            memory: 128Mi
          requests:
            cpu: 100m
            memory: 128Mi
        ports:
        - {containerPort: 53, protocol: UDP, name: udp-53}
        - {containerPort: 53, protocol: TCP, name: tcp-53}
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
            scheme: HTTP
          initialDelaySeconds: 60
          periodSeconds: 10
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 5
        readinessProbe:
          httpGet:
            path: /ready
            port: 8181
            scheme: HTTP
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 5
      volumes:
        - name: config-volume
          configMap:
            name: kube-dns
            items:
            - key: Corefile
              path: Corefile
